---
layout: post
title: "Day 32 - XGBoost Model Training"
date: 2025-07-09
author: Omotolani Bello
permalink: /day32.html
tags: ["Trustworthy Multimodal AI for Skin Cancer Detection"]

what_i_learned: |
  We continued working on our project code, this time using the XGBoost model to train our dataset. There was a small issue with encoding the columns properly, but we managed to work through it without too much delay. After sorting that out, we were able to successfully train the model. The classification report showed that the model performed well, and seeing that reflected in the matrix gave a better sense of how it’s handling the data. It felt like a productive step forward, especially as we try out different approaches to improve performance.
  
  We cleaned the dataset off the null values and then reset the indexes to keep everything organized. After that, we mapped the Fitzpatrick scale from Roman numerals to grouped categories like 1&2, 3&4, which helps simplify the classification. It made the dataset easier to work with and more structured for training. These small steps helped prepare the data for the next phase of modeling. It’s a good reminder that careful preparation on the front end makes the rest of the process smoother.



blockers: |
  No blockers.

reflection: |
  Getting the XGBoost model to work today felt like a solid step. Even though we ran into a small issue with column encoding, it didn’t hold us back for long. Seeing the model train successfully and getting a good accuracy score in the classification report was reassuring. It helped me feel more confident about trying out different models and comparing results. The process is still trial and error, but moments like this show that we're moving in the right direction.
---
